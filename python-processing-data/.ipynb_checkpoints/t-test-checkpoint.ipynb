{
 "metadata": {
  "name": "",
  "signature": "sha256:58c8007a502a8eb4a1ff067d8ba640cc60abe94b12acb03da3c92a54a1b76495"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "T-Test for Sample Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will be using a <b>1-sample t-test</b>.\n",
      "The 1-sample t-test is used when we want to compare a sample mean to a population mean (which we already know). \n",
      "We can infer our population mean to be the index average. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import ttest_1samp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also need to work with the non-parametric option. We can only use the 1-sample t-test if the data is normal from the normality set.<br> If not, <b>we need some non-parametric option</b>."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is the non-parametric equivalent to 2-sample t-test\n",
      "from scipy.stats import mannwhitneyu\n",
      "# The only way to do the equivalent of 1-sample t-test\n",
      "# 1-Sample Sign Test or 1-Sample Wilcoxon Test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Example of a ttest_1_sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_sample_data = [177.3, 182.7, 169.6, 176.3, 180.3, 179.4, 178.5, 177.2, 181.8, 176.5]\n",
      "one_sample = ttest_1samp(one_sample_data, 175.3)\n",
      "print \"The t-statistic is %.3f and the p-value is %.3f.\" % one_sample"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The t-statistic is 2.296 and the p-value is 0.047.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we can conclude that the mean of our sample is significantly different <b>(p\u2004<\u2004 0.055)</b> from the average index sample. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Let's try it with this new explanation:</b><br><br>\n",
      "1-2) Stock log return is log(price_t/price_(t-1)). You should have two separate time series of log returns, one for each stock and one for the index. You can then use a one-tailed two sample paired t-test to see if the stock log returns come from a distribution with a higher mean than the index log returns.\n",
      "\n",
      "Otherwise you can use the log relative stock returns only, which will give you only one time series. Then you would you one tailed one sample t-test to check if the log relative returns come from a distribution with a mean significantly higher than 0.\n",
      "\n",
      "3) CUSUM would give you the start (t_0) and end (t_n) points of an investment horizon. You could do two things: a) only label the feature vector at time t_0 (by running a t-test on the weekly time series between t_0 and t_n). This way there will be one labeled feature vector per CUSUM investment horizon for each company. The problem with this is that you might get too little training data. If this is the case you could try option b) label as many feature vectors between t_0 and t_n as possible by running a separate t-test on the time series [t_0, t_n],  [t_1, t_n], [t_2, t_n]... [t_(n-1), t_n], as long as your weekly time series sample size is large enough to ensure 80% power of your t-test."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>So what we should do is:</b> Just work with the log relative stock returns because python can give us a 1 sample t-test that returns 2 tailed. BUT because we know our distribution to be gaussian (otherwise we can't use this), then we can just divide the 2 sample  by 2 to get 1 sample!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pickle import load\n",
      "import numpy as np\n",
      "data = load(open('../storage/wu-processed-data.pkl', 'rb'))\n",
      "index = load(open('../storage/wu-processed-index.pkl', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This function searches by ticker, i.e. 'AA'\n",
      "def search_by_ticker(data, ticker):\n",
      "    return np.array([i for i in data if i[0] == ticker])\n",
      "\n",
      "# This functions searches by index i.e. Log Revenue Return\n",
      "def search_by_index(index, data, spec):\n",
      "    idx = np.where(index == spec)[0][0]\n",
      "    return np.array([i[idx] for i in data])\n",
      "\n",
      "# Combining these let's us get specific columns of specific rows\n",
      "AA = search_by_ticker(data, 'AA')\n",
      "return_AA = search_by_index(index, AA, 'Log Revenue Return')\n",
      "stock_AA = search_by_index(index, AA, 'Stock Adjusted Closing Price')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def floatify(data):\n",
      "    return np.array([float(i) for i in data])\n",
      "\n",
      "def remove_nan(data):\n",
      "    return data[~np.isnan(data)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "return_AA = floatify(return_AA)\n",
      "return_AA = remove_nan(return_AA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SO WE SHOULD REALLY CHECK THAT IT IS NORMAL. \n",
      "import scipy.stats as stats\n",
      "def am_i_normal(data):\n",
      "    chi, p_val = stats.normaltest(data)\n",
      "    print (chi, p_val)\n",
      "    if p_val < 0.055:\n",
      "        return False\n",
      "    return True\n",
      "am_i_normal(return_AA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3.5726586110480971, 0.16757415562757463)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# THIS IS NORMAL, SO LET'S TRY T-TEST\n",
      "t_stat, prob = ttest_1samp(return_AA, 0.0)\n",
      "prob / 2 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "0.15051542408675747"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"because the one-sided tests can be backed out from the two-sided tests. (With symmetric distributions one-sided p-value is just half of the two-sided pvalue)\n",
      "It goes on to say that scipy always gives the test statistic as signed. This means that given p and t values from a two-tailed test, you would reject the null hypothesis of a greater-than test when p/2 < alpha and t > 0, and of a less-than test when p/2 < alpha and t < 0.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This works because the t_stat is SIGNED. Thus if it is > 0, \n",
      "# then we can reject in favor of a greater than alternative. \n",
      "def one_tailed_one_sample_t_test(data, alpha=0.055, hypothesis=\"greater\"):\n",
      "    if hypothesis not in [\"greater\", \"less\"]:\n",
      "        return \"Error: No hypothesis.\"\n",
      "    t_stat, prob = ttest_1samp(data, 0.0)\n",
      "    # Depends on what the hypothesis is\n",
      "    if hypothesis == \"greater\": # t-stat is the indicator\n",
      "        result = True if (t_stat > 0 and prob / 2 < alpha) else False\n",
      "    else:\n",
      "        result = True if (t_stat < 0 and prob / 2 < alpha) else False\n",
      "    return result\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>After I also calc log stock and index</b>, we will be doing the 2 sample because I feel like that is cleaner and also allows me to use mannwhitney which I am more familiar with. <b>Also I don't know if python an equivalent for 1 sample nonparametric...</b>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import ttest_ind, mannwhitneyu\n",
      "def one_tailed_two_sample_t_test(data1, data2, alpha=0.055, hypothesis=\"greater\"):\n",
      "    if hypothesis not in [\"greater\", \"less\"]:\n",
      "        return \"Error: No hypothesis.\"\n",
      "    normality1 = am_i_normal(data1)\n",
      "    normality2 = am_i_normal(data2)\n",
      "    \n",
      "    if normality1 and normality2:\n",
      "        t_stat, prob = ttest_ind(data1, data2, equal_var=True)\n",
      "        if hypothesis == \"greater\": # t-stat is the indicator\n",
      "            result = True if (t_stat > 0 and prob / 2 < alpha) else False\n",
      "        else:\n",
      "            result = True if (t_stat < 0 and prob / 2 < alpha) else False\n",
      "    else:\n",
      "        u_stat, prob = mannwhitneyu(data1, data2)\n",
      "        if prob < 0.055:\n",
      "            # All I know at this point is that the distributions are distinct. \n",
      "            # I have to compare raw medians to know which way\n",
      "            # Let data1 be stock data\n",
      "            result = np.median(data1) > np.median(data2)                            \n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.median(test_data) > np.median(shift_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}