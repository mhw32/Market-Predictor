{
 "metadata": {
  "name": "",
  "signature": "sha256:ad9c87010a5308e7ec9f9b19af05252a289e27520596ee5e86c264140290968c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Let's try a bunch of feature selection tactics"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Recursive Feature Elimination"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recursively removes attributes and builds a model with those attributes that remain. Uses accuracy to identify which attributes work to predicting the target attribute."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Recursive Feature Elimination\n",
      "from sklearn import datasets\n",
      "from sklearn.feature_selection import RFE\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "# Load a temporary data set\n",
      "dataset = datasets.load_iris()\n",
      "# Create a base classifier to evaluate a subset of attr\n",
      "model = LogisticRegression()\n",
      "# Create the RFE model + select 3 attributes\n",
      "rfe = RFE(model, 3) # <-- how many features to select. \n",
      "rfe = rfe.fit(dataset.data, dataset.target)\n",
      "# Summarize the selection of the attr\n",
      "print(rfe.support_)\n",
      "print(rfe.ranking_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[False  True  True  True]\n",
        "[2 1 1 1]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def recursive_selection(vectors, labels, num):\n",
      "    model = LogisticRegression() \n",
      "    rfe   = RFE(model, num)\n",
      "    rfe   = rfe.fit(vectors, labels)\n",
      "    return rfe.support_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Measuring Feature Importance via ExtraTreesClassifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basically quantifies the features to see which ones are \"more important\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Feature Importance\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "# load the iris datasets\n",
      "dataset = datasets.load_iris()\n",
      "# fit an Extra Trees model to the data\n",
      "model = ExtraTreesClassifier()\n",
      "model.fit(dataset.data, dataset.target)\n",
      "# display the relative importance of each attribute\n",
      "print(model.feature_importances_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.06270627  0.09101527  0.26196329  0.58431517]\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = model.feature_importances_\n",
      "test = [(i,j) for i,j in enumerate(tmp)]\n",
      "test = sorted(test, key=lambda x: x[1])\n",
      "indices = [i[0] for i in test]\n",
      "indices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[0, 1, 2, 3]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extra_trees(vectors, labels):\n",
      "    # fit an Extra Trees model to the data\n",
      "    model = ExtraTreesClassifier()\n",
      "    model.fit(vectors, labels)\n",
      "    # display the relative importance of each attribute\n",
      "    print(model.feature_importances_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Chi Squared Test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Univariate feature selection works by selecting the best features based on univariate statistical tests."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "from sklearn.feature_selection import chi2\n",
      "iris = load_iris()\n",
      "X, y = iris.data, iris.target\n",
      "X_new = SelectKBest(chi2, k=1).fit_transform(X, y)\n",
      "X_new.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "(150, 1)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chi2_selection(vectors, labels, num):\n",
      "    if num >= vectors.shape[1]:\n",
      "        return 'Error: features selected must be less than total number of features'\n",
      "    X_new = SelectKBest(chi2, k=num).fit_transform(vectors, labels)\n",
      "    return X_new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}